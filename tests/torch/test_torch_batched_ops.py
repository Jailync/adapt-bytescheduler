#!/usr/bin/python3

import torch
import byteps.torch as bps

print("=======================================================")
print("testing batched_unfuse_ for GPU tensors")
aa = torch.arange(14, dtype=torch.float32).reshape(7,2).cuda()
bb = torch.zeros(2, dtype=torch.float32).reshape(1,2).cuda()
cc = torch.zeros(4, dtype=torch.float32).reshape(2,2).cuda()
dd = torch.zeros(6, dtype=torch.float32).reshape(3,2).cuda()
ee = torch.zeros(1, dtype=torch.float32).reshape(1,1).cuda()
ff = torch.zeros(1, dtype=torch.float32).reshape(1,1).cuda()
bps.batched_unfuse_(aa, [bb, cc, dd, ee, ff])
assert torch.all(bb == aa[0:1,:])
assert torch.all(cc == aa[1:3,:])
assert torch.all(dd == aa[3:6,:])
assert torch.all(ee == aa[6,0])
assert torch.all(ff == aa[6,1])

print("=======================================================")
print("testing batched_unfuse_ for GPU tensors")
aa = torch.arange(14, dtype=torch.float32).reshape(7,2).cuda()
bb = torch.zeros(2, dtype=torch.float32).reshape(1,2).cuda()
cc = torch.zeros(4, dtype=torch.float32).reshape(2,2).cuda()
dd = None
ee = torch.zeros(1, dtype=torch.float32).reshape(1,1).cuda()
ff = torch.zeros(1, dtype=torch.float32).reshape(1,1).cuda()
bps.batched_unfuse_(aa, [bb, cc, dd, ee, ff])
assert torch.all(bb == aa[0:1,:])
assert torch.all(cc == aa[1:3,:])
assert torch.all(ee == aa[3,0])
assert torch.all(ff == aa[3,1])

print("=======================================================")
print("testing batched_unfuse_ for CPU tensors")
aa = torch.arange(14, dtype=torch.float32).reshape(7,2)
bb = torch.zeros(2, dtype=torch.float32).reshape(1,2)
cc = torch.zeros(4, dtype=torch.float32).reshape(2,2)
dd = torch.zeros(6, dtype=torch.float32).reshape(3,2)
ee = torch.zeros(1, dtype=torch.float32).reshape(1,1)
ff = torch.zeros(1, dtype=torch.float32).reshape(1,1)
bps.batched_unfuse_(aa, [bb, cc, dd, ee, ff])
assert torch.all(bb == aa[0:1,:])
assert torch.all(cc == aa[1:3,:])
assert torch.all(dd == aa[3:6,:])
assert torch.all(ee == aa[6,0])
assert torch.all(ff == aa[6,1])

print("=======================================================")
print("testing batched_fuse_ for GPU tensors")
aa = torch.zeros(14, dtype=torch.float32).reshape(7,2).cuda()
bb = torch.rand(2, dtype=torch.float32).reshape(1,2).cuda()
cc = torch.rand(4, dtype=torch.float32).reshape(2,2).cuda()
dd = torch.rand(6, dtype=torch.float32).reshape(3,2).cuda()
ee = torch.rand(1, dtype=torch.float32).reshape(1,1).cuda()
ff = torch.rand(1, dtype=torch.float32).reshape(1,1).cuda()
bps.batched_fuse_([bb, cc, dd, ee, ff], aa)
assert torch.all(bb == aa[0:1,:])
assert torch.all(cc == aa[1:3,:])
assert torch.all(dd == aa[3:6,:])
assert torch.all(ee == aa[6,0])
assert torch.all(ff == aa[6,1])

print("=======================================================")
print("testing batched_fuse_ for GPU tensors including None tensors")
aa = torch.zeros(14, dtype=torch.float32).reshape(7,2).cuda()
bb = torch.rand(2, dtype=torch.float32).reshape(1,2).cuda()
cc = torch.rand(4, dtype=torch.float32).reshape(2,2).cuda()
dd = None
ee = torch.rand(1, dtype=torch.float32).reshape(1,1).cuda()
ff = torch.rand(1, dtype=torch.float32).reshape(1,1).cuda()
bps.batched_fuse_([bb, cc, dd, ee, ff], aa)
assert torch.all(bb == aa[0:1,:])
assert torch.all(cc == aa[1:3,:])
assert torch.all(ee == aa[3,0])
assert torch.all(ff == aa[3,1])

print("=======================================================")
print("testing batched_fuse_ for CPU tensors")
aa = torch.zeros(14, dtype=torch.float32).reshape(7,2)
bb = torch.rand(2, dtype=torch.float32).reshape(1,2)
cc = torch.rand(4, dtype=torch.float32).reshape(2,2)
dd = torch.rand(6, dtype=torch.float32).reshape(3,2)
ee = torch.rand(1, dtype=torch.float32).reshape(1,1)
ff = torch.rand(1, dtype=torch.float32).reshape(1,1)
bps.batched_fuse_([bb, cc, dd, ee, ff], aa)
assert torch.all(bb == aa[0:1,:])
assert torch.all(cc == aa[1:3,:])
assert torch.all(dd == aa[3:6,:])
assert torch.all(ee == aa[6,0])
assert torch.all(ff == aa[6,1])

print("=======================================================")
print("testing batched_zero_ with GPU tensors")
bb = torch.rand(2, dtype=torch.float32).reshape(1,2).cuda()
cc = torch.rand(4, dtype=torch.float32).reshape(2,2).cuda()
dd = torch.rand(6, dtype=torch.float32).reshape(3,2).cuda()
ee = torch.rand(1, dtype=torch.float32).reshape(1,1).cuda()
ff = torch.rand(1, dtype=torch.float32).reshape(1,1).cuda()
bps.batched_zero_([bb, cc, dd, ee, ff])
assert torch.all(bb == 0)
assert torch.all(cc == 0)
assert torch.all(dd == 0)
assert torch.all(ee == 0)
assert torch.all(ff == 0)

print("=======================================================")
print("testing batched_zero_ with GPU tensors including None tensors")
bb = torch.rand(2, dtype=torch.float32).reshape(1,2).cuda()
cc = torch.rand(4, dtype=torch.float32).reshape(2,2).cuda()
dd = None
ee = torch.rand(1, dtype=torch.float32).reshape(1,1).cuda()
ff = torch.rand(1, dtype=torch.float32).reshape(1,1).cuda()
bps.batched_zero_([bb, cc, dd, ee, ff])
assert torch.all(bb == 0)
assert torch.all(cc == 0)
assert torch.all(ee == 0)
assert torch.all(ff == 0)

print("=======================================================")
print("testing batched_zero_ with CPU tensors")
bb = torch.rand(2, dtype=torch.float32).reshape(1,2)
cc = torch.rand(4, dtype=torch.float32).reshape(2,2)
dd = torch.rand(6, dtype=torch.float32).reshape(3,2)
ee = torch.rand(1, dtype=torch.float32).reshape(1,1)
ff = torch.rand(1, dtype=torch.float32).reshape(1,1)
bps.batched_zero_([bb, cc, dd, ee, ff])
assert torch.all(bb == 0)
assert torch.all(cc == 0)
assert torch.all(dd == 0)
assert torch.all(ee == 0)
assert torch.all(ff == 0)
